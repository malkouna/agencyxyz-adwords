<?php
/*
 * TODO: make this configurable on admin page.
 */
$hosts = array(
array(
    'id' => 1, 
    'url' => 'http://www.alphamagazine.com.au', 
    'pages' => 0, 
    'client_email' => 'alpha@agencyxyz.com',
//'client_email' => 'client_1+malkouna@gmail.com',
    'number_of_keywords' => 50,
    'article_matching_pattern' => '/[a-zA-z+]+,([0-9]+)$/',
    'article_css_selector' => '.article-copy', // This is the div that is used to target content
),
);

define('HOSTS', serialize($hosts));

//function crawler_cron() {
//  crawler_all();
//}

$pages = 0;

function crawler_crawl_all() {
	global $posts;

	$hosts = unserialize(HOSTS);
	foreach($hosts as $host) {
		/*
		 * Get all links for pages in current url
		 */
		crawler_crawl_host($host);
		/*
		 * Get and save keyword suggestions for this host
		 */
		crawler_get_keywords($host);
		/*
		 * now create an adgroup (limit 1000 per campaign) for each keyword suggestion
		 */
		crawler_update_adwords($host);
	}
}

function crawler_crawl_alpha_only() {
	global $pages;

	$hosts = unserialize(HOSTS);
	/*
	 * TODO: Only does the first host atm.
	 */
	$host = $hosts[0];
	$url = $host['url'];
	if (!preg_match("[^https?://]", $url)) {
		drupal_set_message('Invalid url in settings: ' . $url, 'error');
		return;
	}
	/* Make sure urls are in lower case */
	$url = strtolower($url);
	$base_url = $url;
	/*
	 * If entered url doesn't have a trailing slash then add one
	 */
	if (!preg_match("[/$]", $base_url)) {
		$base_url .= '/';
	}
	 
	/*
	 * Clear database tables
	 */
	//db_query("DELETE FROM {adwords_crawler_links} WHERE host_id = %d", $host['id']);
	//db_query("DELETE FROM {adwords_crawler_keywords} WHERE host_id = %d", $host['id']);
	// Following query will force rerawl of pages
	db_query("UPDATE {adwords_crawler_links} SET crawled = 0 WHERE host_id = %d", $host['id']);
	
	/*
	* write first url to start crawl
	*/
	$recrawl = db_fetch_object(db_query("
    SELECT *
    FROM {adwords_crawler_links} 
    WHERE host_id = %d AND url = '%s'", $host['id'], $url));
	if($recrawl) {
		$recrawl->crawled = 0;
		drupal_write_record('adwords_crawler_links', $recrawl, array('id'));
	}
	else {
		$link_record = new stdClass();
		//$link_record->id = null;
		$link_record->url = $url;
		$link_record->host_id = $host['id'];
		$link_record->processed = 0;
		$link_record->crawled = 0;
		drupal_write_record('adwords_crawler_links', $link_record);
	}

	$pages = 1;

	$batch = array(
    'title' => t('Crawling...'),
    'operations' => array(
	array('crawler_crawl_url', array($host)),
	array('crawler_get_keywords', array($host)),
	array('crawler_update_adwords', array($host)),
	),
    'finished' => 'crawler_crawl_only_finished',
    'pages'
    );
    batch_set($batch);
}

function crawler_crawl_only_finished($success, $results, $operations) {
	if ($success) {
		$message = 'Crawl completed';
	}
	else {
		$message = 'Error with crawl stage';
	}
	drupal_set_message($message);
}

function crawler_crawl_host($host, &$context) {
	global $pages;

	/*
	 * Seeding function, that will check the base URL and
	 * save for all relative urls
	 */
	$url = $host['url'];
	if (!preg_match("[^https?://]", $url)) {
		drupal_set_message('Invalid url in settings: ' . $url, 'error');
		return;
	}
	/* Make sure urls are in lower case */
	$url = strtolower($url);
	$base_url = $url;
	/*
	 * If entered url doesn't have a trailing slash then add one
	 */
	if (!preg_match("[/$]", $base_url)) {
		$base_url .= '/';
	}

	/* reset counter here for each crawl */
	$pages = 1;
	 
	crawler_crawl_url($url, $base_url, $host);
}

function crawler_get_campaign_by_name($user, $name) {
	try {
		// Get the CampaignService.
		$campaignService = $user->GetCampaignService('v201008');

		// Create selector.
		$selector = new CampaignSelector();

		// Get all campaigns.
		$page = $campaignService->get($selector);
		if (isset($page->entries)) {
			foreach ($page->entries as $campaign) {
				if($campaign->name == $name) {
					if ($campaign->status != 'PAUSED') {
						$update_campaign = new Campaign;  // Have to use new campaign object so that other parameters don't get set.
						$update_campaign->id = $campaign->id;
						$update_campaign->status = 'PAUSED';
						// $campaign->startDate = date("Ymd");  // Need to set start date to today to avoid exception
						$operation = new CampaignOperation();
						$operation->operand = $update_campaign;
						$operation->operator = 'SET';

						$operations = array($operation);

						// Update campaign.
						$result = $campaignService->mutate($operations);
						if(!isset($result->value)) {
							watchdog('adwords_crawler', t('Unable to unpause campaign @campaign', array('@campaign' => $campaign->name)), WATCHDOG_ERROR);
						}
					}
					// If I find a campaign with this name return make sure it's paused and return the id
					return $campaign->id;
				}
			}
		}
	}
	catch (exception $e) {
		// watchdog('adwords_crawler', t('crawler_get_campaign_by_name generated exception' . print_r($e, true)), NULL, WATCHDOG_ERROR);
		watchdog('adwords_crawler', t('crawler_get_campaign_by_name generated exception %faultstring'), array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
	}
	return null;
}

function crawler_get_adgroup_by_name($user, $name, $campaign_id) {
	try {
		// Get the AdGroupService.
		$adGroupService = $user->GetAdGroupService('v201008');

		//  Create selector.
		$selector = new AdGroupSelector();
		$selector->campaignIds = array($campaign_id);

		// Get all ad groups.
		$page = $adGroupService->get($selector);
		if (isset($page->entries)) {
			foreach ($page->entries as $adGroup) {
				if($adGroup->name == $name) {
					// If I find a campaign with this name return the id
					return $adGroup->id;
				}
			}
		}
	}
	catch (exception $e) {
		watchdog('adwords_crawler', 'crawler_get_adgroup_by_name generated exception %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
	}
	return null;
}

function crawler_add_adgroup($user, $name, $campaign_id) {
	/*
	 * See if we have a adgroup with this name, if so return that id
	 */
	if($adgroup_id = crawler_get_adgroup_by_name($user, $name, $campaign_id)) {
		return $adgroup_id;
	}
	/* otherwise add a new adgroup */
	try {
		// Get the AdGroupService.
		$adGroupService = $user->GetAdGroupService('v201008');

		// Create ad group.
		$adGroup = new AdGroup();
		$adGroup->name = $name;
		$adGroup->status = 'PAUSED';
		$adGroup->campaignId = $campaign_id; // ID of just created campaign

		// Create ad group bid.
		$adGroupBids = new ManualCPCAdGroupBids();
		$adGroupBids->keywordMaxCpc = new Bid(new Money(1000000));
		$adGroup->bids = $adGroupBids;

		// Create operations.
		$operation = new AdGroupOperation();
		$operation->operand = $adGroup;
		$operation->operator = 'ADD';

		$operations = array($operation);

		// Add ad group.
		$result = $adGroupService->mutate($operations);

		if(isset($result->value)) {
			foreach ($result->value as $adGroup) {
				watchdog('adwords_crawler', t('AdGroup @adgroup added', array('@adgroup' => $adGroup->name)));
				return $adGroup->id;
			}
		}
		else {
			watchdog('adwords_crawler', t('AdGroup @adgroup not added', array('@adgroup' => $adGroup->name)));
		}
	}
	catch (Exception $e) {
		watchdog('adwords_crawler', 'Exception adding AdGroupd %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
	}
	return null;
}

function crawler_add_campaign($user, $title) {
	$campaign_name = 'Auto Article Campaign - ' . $title;
	/*
	 * See if we have a campaign with this name, if so return that id
	 */
	if($campaign_id = crawler_get_campaign_by_name($user, $campaign_name)) {
		return $campaign_id;
	}

	/* otherwise add a new campaign */
	try {
		// Get the CampaignService.
		$campaignService = $user->GetCampaignService('v201008');

		// Create campaign.
		$campaign = new Campaign();
		$campaign->name = $campaign_name;
		$campaign->status = 'PAUSED';
		$campaign->biddingStrategy = new ManualCPC();

		$budget = new Budget();
		$budget->period = 'DAILY';
		$budget->amount = new Money((float) 50000000);
		$budget->deliveryMethod = 'STANDARD';
		$campaign->budget = $budget;

		// Create operations.
		$operation = new CampaignOperation();
		$operation->operand = $campaign;
		$operation->operator = 'ADD';

		$operations = array($operation);

		// Add campaign.
		$result = $campaignService->mutate($operations);

		// Display campaigns.  TODO: check what happens on duplicate campaign
		if (isset($result->value)) {
			foreach ($result->value as $campaign) {
				watchdog('adwords_crawler', t('Campaign @campaign added', array('@campaign' => $campaign->name)));
				/* Campaign added successfully, set target location to AU
				 * Get the CampaignTargetService.
				 */
				//
				$campaignTargetService = $user->GetCampaignTargetService('v201008');

				// Create geo targets.
				$geoTargetList = new GeoTargetList();
				$geoTargetList->campaignId = $campaignId;
				$geoTargetList->targets = array(new CountryTarget('AU'));

  		  $operations = array($geoTargetOperation);

        // Set campaign targets.
        $target_result = $campaignTargetService->mutate($operations);
        if(!isset($target_result->value)) {
        	watchdog('adwords_cralwer', t('Could not set geo targets for campaign @campaign', array('@campaign' => $campaign->name)));
        }
				return $campaign->id;
			}
		}
		else {
			watchdog('adwords_crawler', t('Campaign @campaign not added', array('@campaign' => $campaign->name)));
			return null;
		}
	}
	catch (Exception $e) {
		watchdog('adwords_crawler', 'Exception adding campaign %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
	}
	return null;
}

function crawler_update_adwords($host, &$context) {
	/*
	 * Keywords are created under an adgroup which in turn are created
	 * under a campaign, so first create campaign.
	 */
	$link_query = db_query("
    SELECT * 
    FROM {adwords_crawler_links} 
    WHERE host_id = %d
    AND article_id IS NOT NULL
    AND processed = 0", $host['id']);

	if($link_result = db_fetch_object($link_query)) {
		$context['finished'] = 0;
		$context['message'] = t('Updating adwords for %url', array('%url' => $link_result->url));
		/* Update status for this url */
		$link_result->processed = 1;
		drupal_write_record('adwords_crawler_links', $link_result, array('id'));
	}
	else { // finished!
		$context['finished'] = 1;
		return;
	}
	/*
	 * Connect to the adwords server using a client ID in this instance
	 */
	$user = crawler_adwords_login($host['client_email']);
	if (!$user) {
		watchdog('adwords_crawler', t('Cannot log into AdWords server'), NULL, WATCHDOG_ERROR);
		return;
	}

	/* Update this link as processed */
	//  $link_record = new stdClass();
	//  $link_record->id = $link_result->id;
	//  $link_record->processed = 1;
	//  drupal_write_record('adwords_crawler_links', $link_record, array('id'));

	// Add the campaign
	if(!$campaign_id = crawler_add_campaign($user, $link_result->breadcrumb)) {
		continue; // If there was a problem with the campaign add then do next link
	}
	$adgroup_name = $link_result->article_id . ' - ' . $link_result->title;
	if(!$adgroup_id = crawler_add_adgroup($user, $adgroup_name, $campaign_id)) {
		continue; // If there was a problem with the adgroup add then do next link
	}
	try {
		// Now have adgroup add all the keywords for this url
		$keyword_query = db_query("SELECT * FROM {adwords_crawler_keywords} WHERE url = '%s'", $link_result->url);
		while($keyword_result = db_fetch_object($keyword_query)) {
			// Get the AdGroupCriterionService.
			$adGroupCriterionService = $user->GetAdGroupCriterionService('v201008');

			// Create keyword.
			$keyword = new Keyword();
			$keyword->text = $keyword_result->keyword;
			$keyword->matchType = 'BROAD';

			// Create biddable ad group criterion.
			$keywordAdGroupCriterion = new BiddableAdGroupCriterion();
			$keywordAdGroupCriterion->adGroupId = $adgroup_id;
			$keywordAdGroupCriterion->criterion = $keyword;

			// Create operations.
			$keywordAdGroupCriterionOperation = new AdGroupCriterionOperation();
			$keywordAdGroupCriterionOperation->operand = $keywordAdGroupCriterion;
			$keywordAdGroupCriterionOperation->operator = 'ADD';

			$operations = array($keywordAdGroupCriterionOperation);

			// Add ad group criteria.
			$result = $adGroupCriterionService->mutate($operations);

			// Display ad group criteria.
			if (!isset($result->value)) {
				//          foreach ($result->value as $adGroupCriterion) {
				//            watchdog('adwords_crawler', 'Ad group criterion with ad group id "'
				//                . $adGroupCriterion->adGroupId . '", criterion id "'
				//                . $adGroupCriterion->criterion->id . ', and type "'
				//                . $adGroupCriterion->criterion->CriterionType . "\" was added.");
				//          }
				//        } else {
				watchdog('adwords_crawler', "No ad group criteria were added.");
		}
	}
}
catch (Exception $e) {
	watchdog('adwords_crawler', 'Exception defining ad group criteria %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
}

try {
	// Get the AdGroupAdService and add ads.
	$adGroupAdService = $user->GetAdGroupAdService('v201008');

	// Create a text ad for this adgroup
	// Create text ad.
	$textAd = new TextAd();
	$headline = substr($link_result->title, 0, 25);
	$headline = substr($headline, 0, strrpos($headline, ' '));
	$textAd->headline = $headline;
	$textAd->url = $link_result->url;
	$description1 = substr($link_result->description, 0, 35);
	$description1 = substr($description1, 0, strrpos($description1, ' '));
	if(!$description1) {
		$description1 = $headline;
	}
	$description2 = substr($link_result->description, strlen($description1), 35);
	$description2 = substr($description2, 0, strrpos($description2, ' '));
	if(!$description2) {
		$description2 = $headline;
	}
	$textAd->description1 = $description1;
	$textAd->description2 = $description2;
	$display_url = explode("/", $link_result->url);
	// Pop off the article bit at the end
	array_pop($display_url);
	$textAd->displayUrl = implode("/", $display_url);

	// Create ad group ad.
	$textAdGroupAd = new AdGroupAd();
	$textAdGroupAd->adGroupId = $adgroup_id;
	$textAdGroupAd->ad = $textAd;

	// Create operations.
	$textAdGroupAdOperation = new AdGroupAdOperation();
	$textAdGroupAdOperation->operand = $textAdGroupAd;
	$textAdGroupAdOperation->operator = 'ADD';

	$operations = array($textAdGroupAdOperation);

	// Add ads.
	$result = $adGroupAdService->mutate($operations);

	if (isset($result->value)) {
		foreach ($result->value as $adGroupAd) {
			watchdog('adwords_crawler', t('Ad added to AdGroup @adgroup with id @adid', array('@adgroup' => $adGroupAd->name, '@adid' => $adGroupAd->id)));
		}
	} else {
		watchdog('adwords_crawler', t('Ad not added to AdGroup @adgroup', array('@adgroup' => $adGroup->name)));
	}

}
catch (Exception $e) {
	//      foreach($e->detail->ApiExceptionFault->errors as $error) {
	//        $msg .=
	//      }
	$vars = array(
        '@fault' => $e->faultstring,
        '@headline' => $headline,
        '@description1' => $description1,
        '@description2' => $description2,
	// '@exception' => print_r($e, true)
        '@exception' => $e->faultstring,
	);

	watchdog('adwords_crawler', 'Creating ad failed with exception.  Exception Details: @fault <br/>
        Ad details: <br />
        headline: @headline <br />
        description1: @description1 <br />
        description2: @description2 <br />
        @exception', $vars, WATCHDOG_ERROR);
}
}


function crawler_crawl_url($host, &$context) {

	/*
	 * If we've reached our limit just return, don't process any more links.
	 */
	$pages = db_fetch_object(db_query("
    SELECT COUNT(*) AS pages 
    FROM {adwords_crawler_links} 
    WHERE host_id = %d
    AND article_id IS NOT NULL", $host['id']));

	if($pages->pages >= $host['pages'] && $host['pages'] != 0) { // pages equals zero equals no limit.
		$context['finished'] = 1;
		return;
	}

	/* Get first uncrawled page */
	$query = db_query("SELECT * FROM {adwords_crawler_links} WHERE crawled = 0 AND host_id = %d", $host['id']);
	if($url_result = db_fetch_object($query)) {
		$url = $url_result->url;
		/* Process this crawl */
		$title = htmlqp($url, 'title')->text();
		$context['finished'] = 0;
		$context['message'] = t('Crawling %url', array('%url' => $url));
	}
	else {
		/* Crawl finished, no more pages left to crawl! */
		$context['finished'] = 1;
		return;
	}
	//  if($pages_batch > PAGES_BATCH_LIMIT) {
	//
	//  }
	//drupal_set_message('Crawling ' . $url);


	/*
	 * Let's work out if this is something that matches our article pattern
	 * and save a flag for articles, the breadcrumb, the title and the article id
	 */
	if(preg_match($host['article_matching_pattern'], $url, $matches)) {
		// Try and get something for a description
		$content = str_replace(array("\n", "\t"), "", htmlqp($url, $host['article_css_selector'])->text());
		// Got here, so must be an article
		$article_id = $matches[1];
		$breadcrumbs = explode("/", $url);
		// Shift off the start
		for($i=0; $i<3; $i++) { // get rid of host and http:
			array_shift($breadcrumbs);
		}
		// Pop off the bits that are the host and the article, then implode the rest
		array_pop($breadcrumbs);
		$breadcrumb = implode(" > ", $breadcrumbs);
		$pages++;
	}

	/*
	 * Save updated details for this link from the crawl and mark it
	 * as crawled before getting child links.
	 */
	// $record = new stdClass();
	// $record->id = $result->id;
	$url_result->article_id = $article_id;
	$url_result->title = $title;
	$url_result->breadcrumb = $breadcrumb;
	$url_result->description = $content;
	$url_result->crawled = 1;
	drupal_write_record('adwords_crawler_links', $url_result, array('id'));

	/*
	 * Get all <a> elements in provided url
	 */
	$links = htmlqp($url, 'a');
	foreach($links as $link) {

		/* Make sure only dealing with lower case */
		$link_url = strtolower($link->attr('href'));
		//drupal_set_message('Link found ' . $link_url);
		/*
		* Check for exceptions like "mailto:" links and just grab next link
		* TODO: add more exceptions to regex below
		*/
		if(preg_match("[^mailto:]", $link_url)) {
			continue;
		}
		/*
		 * Prepare link here
		 * If I have a leading slash then remove it
		 */
		if(preg_match("[^/]", $link_url)) {
			$link_url = ltrim($link_url, "/");
		}
		/*
		 * If it's not a full url then prepend base to it.
		 */
		if (!preg_match("[^https?://]", $link_url)) {
			$link_url = $host['url'] . '/' . $link_url;
		}
		/*
		 * check here if this link has been crawled.
		 */
		$domain_check = "[^" . $host['url'] . "]";
		if(preg_match($domain_check, $link_url)) {

			/*
			 * recursively crawl this url
			 * TODO: check that this url hasn't been crawled.
			 */

			$query = db_query("SELECT * FROM {adwords_crawler_links} WHERE url = '%s'", $link_url);
			if (db_affected_rows() == 0) { // We haven't crawled this yet
				/*
				* Crawl this child page looking for links.
				*/
				//crawler_crawl_url($link_url, $base_url, $host);
				/*
				* We got here so have a valid link that we want to crawl.
				* Save it to database so controlling batch will crawl it.
				*/
				/*
				 * If we've got to here then this is a new url that
				 * should be saved in the database
				 */
				$link_record = new stdClass();
				//$link_record->id = null;
				$link_record->url = $link_url;
				$link_record->host_id = $host['id'];
				$link_record->crawled = 0;
				drupal_write_record('adwords_crawler_links', $link_record);
			}
		}
	}
}

function crawler_adwords_login($client_login = null) {
	$path = dirname(__FILE__) . '/../src';
	set_include_path(get_include_path() . PATH_SEPARATOR . $path);

	require_once 'Google/Api/Ads/AdWords/Lib/AdWordsUser.php';
	require_once 'Google/Api/Ads/Common/Util/MapUtils.php';

	$ini_file = variable_get('adwords_crawler_sandbox', 1) == 1?'settings-sandbox.ini':'settings.ini';
	$ini_file = dirname(__FILE__) . '/' . $ini_file;
	$developer_token = variable_get('adwords_crawler_sandbox', 1) == 1?variable_get('adwords_crawler_email_address', '') . '++AUD':'5AYQ2vWZgg7pKsE8RjB73g';
	try {
		// Get AdWordsUser from credentials in "../auth.ini"
		// relative to the AdWordsUser.php file's directory.
		$user = new AdWordsUser(
		null,
		variable_get('adwords_crawler_email_address', ''),
		variable_get('adwords_crawler_password', ''),
		$developer_token,
		null,
		null,
		$client_login,
		$ini_file,
		null,
		null,
		null
		);

		// Log SOAP XML request and response.
		$user->LogDefaults();

	}
	catch (Exception $e) {
		watchdog('adwords_crawler', 'Get user exception %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
		return null;
	}

	return $user;
}
/**
 * Function that queries the AdWords API to get keyword suggestions for a url.
 *
 */

function crawler_get_keywords($host, &$context) {
	/*
	 * submit all the urls for a particular host to AdWords to get keyword
	 * suggestions.  Then save them to a database.  Only do this for "articles"
	 */
	$query = db_query("
    SELECT * 
    FROM {adwords_crawler_links} 
    WHERE host_id = %d
    AND article_id IS NOT NULL
    AND keywords_generated = 0", $host['id']);
	/*
	 * Connect to the adwords server
	 */

	if($result = db_fetch_object($query)) {
		$context['finished'] = 0;
		$context['message'] = t('Getting keywords for %url', array('%url' => $result->url));
		/* Update status for this url */
		$result->keywords_generated = 1;
		drupal_write_record('adwords_crawler_links', $result, array('id'));

	}
	else {
		/* Got keywords for all URLs.  finished! */
		$context['finished'] = 1;
		return;
	}

	$user = crawler_adwords_login();
	if (!$user) {
		watchdog('adwords_crawler', t('Cannot log into AdWords server'), NULL, WATCHDOG_ERROR);
		return;
	}

	try {
		// Get the TargetingIdeaService.
		$targetingIdeaService = $user->GetTargetingIdeaService('v201003');

		/*
		 * Now get keywords for each url and save them in the database
		 */
		// Create selector.
		$selector = new TargetingIdeaSelector();
		$selector->requestType = 'IDEAS';
		$selector->ideaType = 'KEYWORD';
		$selector->requestedAttributeTypes =
		array('KEYWORD', 'AVERAGE_TARGETED_MONTHLY_SEARCHES');

		// Set selector paging (required for targeting idea service).
		$paging = new Paging();
		$paging->startIndex = 0;
		$paging->numberResults = $host['number_of_keywords'];
		$selector->paging = $paging;

		// Create related to url search parameter.
		$relatedToUrlSearchParameter = new RelatedToUrlSearchParameter();
		$relatedToUrlSearchParameter->urls = array($result->url);
		$relatedToUrlSearchParameter->includeSubUrls = false;
		$selector->searchParameters = array($relatedToUrlSearchParameter);

		// Create keyword match type search parameter to ensure unique results.
		$keywordMatchTypeSearchParameter = new KeywordMatchTypeSearchParameter();
		$keywordMatchTypeSearchParameter->keywordMatchTypes = array('BROAD');

		$selector->searchParameters =
		array($relatedToUrlSearchParameter, $keywordMatchTypeSearchParameter);

		// Get related keywords.
		$page = $targetingIdeaService->get($selector);

		// save related keywords.
		if (isset($page->entries)) {
			foreach ($page->entries as $targetingIdea) {
				$data = MapUtils::GetMap($targetingIdea->data);
				$keyword = $data['KEYWORD']->value;
				$keyword_record = new stdClass();
				//$link_record->id = null;
				$keyword_record->url = $result->url;
				$keyword_record->host_id = $host['id'];
				$keyword_record->keyword = $keyword->text;
				drupal_write_record('adwords_crawler_keywords', $keyword_record);

				$averageMonthlySearches =
				isset($data['AVERAGE_TARGETED_MONTHLY_SEARCHES']->value)
				? $data['AVERAGE_TARGETED_MONTHLY_SEARCHES']->value : 0;
				//          printf("Keyword with text '%s', match type '%s', and average monthly "
				//              . "search volume '%s' was found.\n", $keyword->text,
				//              $keyword->matchType, $averageMonthlySearches);
			}
		} else {
			watchdog('adwords_crawler', t("No related keywords were found for %url.", array('%url' => $result->url)));
		}
	}
	catch (Exception $e) {
		watchdog('adwords_crawler', 'Error in getting keywords. %faultstring', array('%faultstring' => $e->faultstring), WATCHDOG_ERROR);
	}
}

/**
 * Implements hook_menu();
 */
function crawler_menu() {
	$items['admin/settings/crawler'] = array(
    'title' => t('AdWords Crawler'),
    'page callback' => 'drupal_get_form',
    'page arguments' => array('crawler_admin_settings'),
    'type' => MENU_NORMAL_ITEM,
    'access arguments' => array('administer adwords'),
	);
	$items['admin/settings/crawler/settings'] = array(
    'title' => t('Settings'),
    'type' => MENU_DEFAULT_LOCAL_TASK,
    'access arguments' => array('administer adwords'),
    'weight' => -10,
	);
	$items['admin/settings/crawler/hosts'] = array(
    'title' => t('Hosts'),
    'page callback' => 'drupal_get_form',
    'page arguments' => array('crawler_admin_hosts'),
    'type' => MENU_LOCAL_TASK,
    'access arguments' => array('administer adwords'),   
	);

	return $items;
}

function crawler_admin_settings() {
	$form['adwords'] = array(
    '#type' => 'fieldset',
    '#title' => t('AdWords server settings'),
	);

	$form['adwords']['adwords_crawler_sandbox'] = array(
    '#type' => 'checkbox',
    '#title' => t('Use Sandbox?'),
    '#default_value' => variable_get('adwords_crawler_sandbox', 1),
	);

	$form['adwords']['adwords_crawler_email_address'] = array(
    '#type' => 'textfield',
    '#title' => t('Email Address'),
    '#default_value' => variable_get('adwords_crawler_email_address', ''),
	);

	$form['adwords']['adwords_crawler_password'] = array(
    '#type' => 'password',
    '#title' => t('Password'),
    '#default_value' => variable_get('adwords_crawler_password', ''),
	);

	return system_settings_form($form);
}

function crawler_admin_hosts($form_state) {


	$form['crawl_alpha_only'] = array(
    '#type' => 'submit',
    '#value' => 'Crawl Alpha',
    '#submit' => array('crawler_crawl_alpha_only'),
	);

	//  $form['crawl_all'] = array(
	//    '#type' => 'submit',
	//    '#value' => 'Crawl All',
	//    '#submit' => array('crawler_crawl_all'),
	//  );

	return $form;
}



